{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNmx6oFH4H0rJ1j/j+COiZq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zhuma5002/Robotics-estimation-and-learning/blob/main/lab3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Setup***"
      ],
      "metadata": {
        "id": "MyBb6Wq9zsnF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-mnist\n",
        "import mnist\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ALk3tyM0xyh",
        "outputId": "a577dceb-e367-4bea-a470-6e446e42649d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-mnist\n",
            "  Downloading python_mnist-0.7-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Downloading python_mnist-0.7-py2.py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: python-mnist\n",
            "Successfully installed python-mnist-0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# Загружаем датасет\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Выводим форму данных\n",
        "print(train_images.shape)  # (60000, 28, 28)\n",
        "print(train_labels.shape)  # (60000,)\n",
        "print(test_images.shape)   # (10000, 28, 28)\n",
        "print(test_labels.shape)   # (10000,)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-aWJZiG1HeE",
        "outputId": "07b2d818-ddf9-41c6-ee33-fa17746427b3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(10000, 28, 28)\n",
            "(10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparing the ***Data***"
      ],
      "metadata": {
        "id": "5L2wc62Q1bIe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# Загружаем данные\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Нормализуем изображения\n",
        "train_images = (train_images / 255.0) - 0.5\n",
        "test_images = (test_images / 255.0) - 0.5\n",
        "\n",
        "# Изменяем форму данных для Conv2D (добавляем канал)\n",
        "train_images = np.expand_dims(train_images, axis=-1)\n",
        "test_images = np.expand_dims(test_images, axis=-1)\n",
        "\n",
        "print(train_images.shape)  # (60000, 28, 28, 1)\n",
        "print(test_images.shape)   # (10000, 28, 28, 1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHppgL-c1cgo",
        "outputId": "769a3f64-67ef-42fb-fde8-24325ae32e8a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28, 1)\n",
            "(10000, 28, 28, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building ***model***"
      ],
      "metadata": {
        "id": "tRH9FRZB174r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# WIP\n",
        "model = Sequential([\n",
        "  # layers...\n",
        "])"
      ],
      "metadata": {
        "id": "eNvXrZnK1-6t"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
        "\n",
        "num_filters = 8\n",
        "filter_size = 3\n",
        "pool_size = 2\n",
        "\n",
        "model = Sequential([\n",
        "  Conv2D(num_filters, filter_size, input_shape=(28, 28, 1)),\n",
        "  MaxPooling2D(pool_size=pool_size),\n",
        "  Flatten(),\n",
        "  Dense(10, activation='softmax'),\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEdIE9Pg2Elw",
        "outputId": "97225d03-478d-449c-fa3a-5c0653256923"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "compiling the model"
      ],
      "metadata": {
        "id": "VSCWv8ES2LuA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "  'adam',\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy'],\n",
        ")"
      ],
      "metadata": {
        "id": "BgkZIZOB2N2x"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "training model"
      ],
      "metadata": {
        "id": "jxAnGRjq2S9c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# Загружаем данные\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Выводим первый лейбл\n",
        "print(train_labels[0])  # Например, 5\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDh2PK7j2Uf6",
        "outputId": "10e2b0c8-c8d5-4992-f58c-8914abf932d8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "model.fit(\n",
        "  train_images,\n",
        "  to_categorical(train_labels),\n",
        "  epochs=3,\n",
        "  validation_data=(test_images, to_categorical(test_labels)),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6DEtqxw2tWc",
        "outputId": "c7a6c4e8-1d3e-4ef1-8cb0-b2abd8e1627f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8170 - loss: 4.8431 - val_accuracy: 0.9262 - val_loss: 0.4821\n",
            "Epoch 2/3\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.9397 - loss: 0.3224 - val_accuracy: 0.9478 - val_loss: 0.2378\n",
            "Epoch 3/3\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 10ms/step - accuracy: 0.9545 - loss: 0.1996 - val_accuracy: 0.9453 - val_loss: 0.2604\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b8a1ac34190>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Загрузка данных MNIST\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Нормализация изображений\n",
        "train_images = (train_images / 255.0) - 0.5\n",
        "test_images = (test_images / 255.0) - 0.5\n",
        "\n",
        "# Изменение формы изображений\n",
        "train_images = np.expand_dims(train_images, axis=-1)\n",
        "test_images = np.expand_dims(test_images, axis=-1)\n",
        "\n",
        "# Гиперпараметры\n",
        "num_filters = 8\n",
        "filter_size = 3\n",
        "pool_size = 2\n",
        "\n",
        "# Построение модели\n",
        "model = Sequential([\n",
        "    Conv2D(num_filters, filter_size, activation='relu', input_shape=(28, 28, 1)),\n",
        "    MaxPooling2D(pool_size=pool_size),\n",
        "    Flatten(),\n",
        "    Dense(10, activation='softmax'),\n",
        "])\n",
        "\n",
        "# Компиляция модели\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Обучение модели\n",
        "model.fit(\n",
        "    train_images,\n",
        "    to_categorical(train_labels),\n",
        "    epochs=3,\n",
        "    validation_data=(test_images, to_categorical(test_labels)),\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5oqvNT23hYG",
        "outputId": "47b4a6b5-b8b9-42b7-9627-a049731fed9f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 10ms/step - accuracy: 0.8471 - loss: 0.5728 - val_accuracy: 0.9629 - val_loss: 0.1327\n",
            "Epoch 2/3\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.9652 - loss: 0.1230 - val_accuracy: 0.9717 - val_loss: 0.0947\n",
            "Epoch 3/3\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.9741 - loss: 0.0883 - val_accuracy: 0.9800 - val_loss: 0.0692\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b8a11f1e110>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "using the model\n"
      ],
      "metadata": {
        "id": "2Nbue9Ld4pYA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights('cnn.weights.h5')\n"
      ],
      "metadata": {
        "id": "9AR-YPCr4sxy"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
        "\n",
        "num_filters = 8\n",
        "filter_size = 3\n",
        "pool_size = 2\n",
        "\n",
        "# Build the model.\n",
        "model = Sequential([\n",
        "  Conv2D(num_filters, filter_size, input_shape=(28, 28, 1)),\n",
        "  MaxPooling2D(pool_size=pool_size),\n",
        "  Flatten(),\n",
        "  Dense(10, activation='softmax'),\n",
        "])\n",
        "\n",
        "# Load the model's saved weights.\n",
        "model.load_weights('cnn.weights.h5')"
      ],
      "metadata": {
        "id": "Tn3DQl4s5SsL"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the first 5 test images.\n",
        "predictions = model.predict(test_images[:5])\n",
        "\n",
        "# Print our model's predictions.\n",
        "print(np.argmax(predictions, axis=1)) # [7, 2, 1, 0, 4]\n",
        "\n",
        "# Check our predictions against the ground truths.\n",
        "print(test_labels[:5]) # [7, 2, 1, 0, 4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5Ta24be5f5W",
        "outputId": "91ccb968-4c50-4d08-9780-3e4ba17aa212"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step\n",
            "[7 1 1 0 4]\n",
            "[7 2 1 0 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "  Conv2D(num_filters, filter_size, input_shape=(28, 28, 1)),\n",
        "  Conv2D(num_filters, filter_size),\n",
        "  MaxPooling2D(pool_size=pool_size),\n",
        "  Flatten(),\n",
        "  Dense(10, activation='softmax'),\n",
        "])"
      ],
      "metadata": {
        "id": "pdHfUqR85tFR"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "model = Sequential([\n",
        "  Conv2D(num_filters, filter_size, input_shape=(28, 28, 1)),\n",
        "  MaxPooling2D(pool_size=pool_size),\n",
        "  Dropout(0.5),\n",
        "  Flatten(),\n",
        "  Dense(10, activation='softmax'),\n",
        "])"
      ],
      "metadata": {
        "id": "KREWzJxl5wvG"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model = Sequential([\n",
        "  Conv2D(num_filters, filter_size, input_shape=(28, 28, 1)),\n",
        "  MaxPooling2D(pool_size=pool_size),\n",
        "  Flatten(),\n",
        "  Dense(64, activation='relu'),\n",
        "  Dense(10, activation='softmax'),\n",
        "])\n"
      ],
      "metadata": {
        "id": "Ci3cpwzT51S3"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# These can be changed, too!\n",
        "num_filters = 8\n",
        "filter_size = 3\n",
        "\n",
        "model = Sequential([\n",
        "  # See https://keras.io/layers/convolutional/#conv2d for more info.\n",
        "  Conv2D(\n",
        "    num_filters,\n",
        "    filter_size,\n",
        "    input_shape=(28, 28, 1),\n",
        "    strides=2,\n",
        "    padding='same',\n",
        "    activation='relu',\n",
        "  ),\n",
        "  MaxPooling2D(pool_size=pool_size),\n",
        "  Flatten(),\n",
        "  Dense(10, activation='softmax'),\n",
        "])"
      ],
      "metadata": {
        "id": "1aNL1Y-b54oH"
      },
      "execution_count": 22,
      "outputs": []
    }
  ]
}